---
title: "OpenCode Integration"
description: "Complete guide to integrating Morpheus AI with OpenCode - a powerful AI coding assistant - using custom provider configuration"
---

# Integrate Morpheus AI with OpenCode

Learn how to set up Morpheus AI as a custom provider in OpenCode, giving you access to powerful, decentralized AI models for coding assistance. This guide walks you through credential setup, provider configuration, and model selection.

## Overview

OpenCode is an open-source AI coding assistant that supports multiple AI providers. By integrating Morpheus AI, you gain access to free, decentralized AI inference through the Morpheus marketplace with models optimized for code generation, reasoning, and development tasks.

<Info>
The Morpheus API Gateway is currently in **Open Beta**, providing free access to AI inference without requiring wallet connections or staking MOR tokens.
</Info>

## Prerequisites

Before you begin, ensure you have:

- **OpenCode** installed on your system
- A **Morpheus AI account** at [app.mor.org](https://app.mor.org)
- Basic familiarity with **JSON configuration files**
- Access to your system's **terminal or command line**

<Steps>
<Step title="Get Your Morpheus AI API Key">
Visit [app.mor.org](https://app.mor.org) and create your API key.

1. Navigate to **Settings** ‚Üí **API Keys**
2. Click **Create New API Key**
3. Provide a descriptive name for the key
4. Copy the generated API key (starts with `sk-`)

<Warning>
Store your API key securely. You won't be able to view it again after the initial creation. Never commit API keys to version control.
</Warning>
</Step>

<Step title="Install OpenCode">
If you haven't already, install OpenCode on your system:

<Tabs>
<Tab title="macOS">
```bash
brew install opencode
```
</Tab>

<Tab title="Linux">
```bash
curl -fsSL https://opencode.ai/install.sh | sh
```
</Tab>

<Tab title="Windows">
```powershell
irm https://opencode.ai/install.ps1 | iex
```
</Tab>
</Tabs>

<Check>
Verify installation by running `opencode --version` in your terminal.
</Check>
</Step>

<Step title="Launch OpenCode">
Start OpenCode for the first time:

```bash
opencode
```

You're now ready to add Morpheus AI credentials.
</Step>
</Steps>

## Adding Morpheus AI Credentials

OpenCode stores API credentials securely in `~/.local/share/opencode/auth.json`. Use the `/connect` command to add your Morpheus AI API key.

### Using the `/connect` Command

<Steps>
<Step title="Execute the connect command">
In the OpenCode terminal, run:

```
/connect
```
</Step>

<Step title="Select 'Other' as the provider">
When prompted to select a provider, choose **Other**:

```
‚îå  Add credential
‚îÇ
‚îÇ ‚óÜ  Select provider
‚îÇ  ...
‚îÇ  ‚óè Other
‚îî
```
</Step>

<Step title="Enter the provider ID">
Type `morpheus-ai` as the provider identifier:

```
‚îå  Add credential
‚îÇ
‚îÇ ‚óá  Enter provider id
‚îÇ  morpheus-ai
‚îî
```

<Info>
The provider ID must exactly match `morpheus-ai` for the configuration to work correctly.
</Info>
</Step>

<Step title="Paste your API key">
Enter your Morpheus AI API key when prompted:

```
‚îå  Add credential
‚îÇ
‚îÇ ‚ñ≤  This only stores a credential for morpheus-ai - you will need to configure it in opencode.json
‚îÇ
‚îÇ ‚óá  Enter your API key
‚îÇ  sk-xxxxxxxxxxxxx
‚îî
```

<Check>
Your Morpheus AI credentials are now securely stored! Next, you'll configure the provider settings.
</Check>
</Step>
</Steps>

## Configuring the Provider

Create or update your OpenCode configuration to define the Morpheus AI provider and available models.

### Configuration Location

<Tabs>
<Tab title="Global Configuration (Recommended)">
Edit the global configuration file:

```
~/.config/opencode/opencode.json
```

This makes Morpheus AI available across all your projects.
</Tab>

<Tab title="Project Configuration">
Create a configuration file in your project root:

```
./opencode.json
```

This makes Morpheus AI available only for the specific project.
</Tab>
</Tabs>

### Full Provider Configuration

Add the following configuration to your `opencode.json` file:

```json opencode.json
{
  "$schema": "https://opencode.ai/config.json",
  "provider": {
    "morpheus-ai": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "Morpheus AI",
      "options": {
        "baseURL": "https://api.mor.org/api/v1"
      },
      "models": {
        "glm-4.6": {
          "name": "GLM 4.6",
          "limit": {
            "context": 200000,
            "output": 65536
          }
        },
        "glm-4.6-web": {
          "name": "GLM 4.6 (Web)",
          "limit": {
            "context": 200000,
            "output": 65536
          }
        },
        "kimi-k2-thinking": {
          "name": "Kimi K2 Thinking",
          "limit": {
            "context": 256000,
            "output": 16384
          }
        },
        "kimi-k2-thinking-web": {
          "name": "Kimi K2 Thinking (Web)",
          "limit": {
            "context": 256000,
            "output": 16384
          }
        },
        "qwen3-coder-480b-a35b-instruct": {
          "name": "Qwen3 Coder 480B",
          "limit": {
            "context": 262144,
            "output": 16384
          },
          "options": {
            "timeout": 600000
          }
        },
        "qwen3-coder-480b-a35b-instruct-web": {
          "name": "Qwen3 Coder 480B (Web)",
          "limit": {
            "context": 262144,
            "output": 16384
          },
          "options": {
            "timeout": 600000
          }
        },
        "hermes-3-llama-3.1-405b": {
          "name": "Hermes 3 Llama 3.1 405B",
          "limit": {
            "context": 128000,
            "output": 8192
          },
          "options": {
            "timeout": 600000
          }
        },
        "hermes-3-llama-3.1-405b-web": {
          "name": "Hermes 3 Llama 3.1 405B (Web)",
          "limit": {
            "context": 128000,
            "output": 8192
          },
          "options": {
            "timeout": 600000
          }
        },
        "qwen3-235b": {
          "name": "Qwen3 235B",
          "limit": {
            "context": 131072,
            "output": 8192
          }
        },
        "qwen3-235b-web": {
          "name": "Qwen3 235B (Web)",
          "limit": {
            "context": 131072,
            "output": 8192
          }
        },
        "qwen3-next-80b": {
          "name": "Qwen3 Next 80B",
          "limit": {
            "context": 131072,
            "output": 4096
          }
        },
        "qwen3-next-80b-web": {
          "name": "Qwen3 Next 80B (Web)",
          "limit": {
            "context": 131072,
            "output": 4096
          }
        },
        "llama-3.3-70b": {
          "name": "Llama 3.3 70B",
          "limit": {
            "context": 128000,
            "output": 8192
          }
        },
        "llama-3.3-70b-web": {
          "name": "Llama 3.3 70B (Web)",
          "limit": {
            "context": 128000,
            "output": 8192
          }
        },
        "mistral-31-24b": {
          "name": "Mistral 31 24B",
          "limit": {
            "context": 128000,
            "output": 8192
          }
        },
        "mistral-31-24b-web": {
          "name": "Mistral 31 24B (Web)",
          "limit": {
            "context": 128000,
            "output": 8192
          }
        },
        "venice-uncensored": {
          "name": "Venice Uncensored",
          "limit": {
            "context": 128000,
            "output": 8192
          }
        },
        "venice-uncensored-web": {
          "name": "Venice Uncensored (Web)",
          "limit": {
            "context": 128000,
            "output": 8192
          }
        },
        "qwen3-4b": {
          "name": "Qwen3 4B",
          "limit": {
            "context": 131072,
            "output": 4096
          }
        },
        "qwen3-4b-web": {
          "name": "Qwen3 4B (Web)",
          "limit": {
            "context": 131072,
            "output": 4096
          }
        },
        "llama-3.2-3b": {
          "name": "Llama 3.2 3B",
          "limit": {
            "context": 32000,
            "output": 4096
          }
        },
        "llama-3.2-3b-web": {
          "name": "Llama 3.2 3B (Web)",
          "limit": {
            "context": 32000,
            "output": 4096
          }
        },
        "hermes-4-14b": {
          "name": "Hermes 4 14B",
          "limit": {
            "context": 128000,
            "output": 4096
          }
        }
      }
    }
  }
}
```

### Understanding the Configuration

<AccordionGroup>
<Accordion title="Provider Settings">
- **npm**: The AI SDK package used (`@ai-sdk/openai-compatible` for OpenAI-compatible APIs)
- **name**: Display name shown in the OpenCode UI
- **options.baseURL**: The Morpheus AI API endpoint (`https://api.mor.org/api/v1`)
</Accordion>

<Accordion title="Model Configuration">
Each model includes:
- **name**: Human-readable model name displayed in the UI
- **limit.context**: Maximum input tokens the model accepts
- **limit.output**: Maximum tokens the model can generate
- **options.timeout**: Optional timeout in milliseconds (used for large models)
</Accordion>

<Accordion title="Web Model Variants">
Models with the `-web` suffix have enhanced capabilities:
- Web search integration
- Current information access
- Browser-optimized responses

Standard models without `-web` are optimized for pure reasoning and code generation tasks.
</Accordion>
</AccordionGroup>

### Minimal Configuration

If you prefer a simpler setup with just essential models:

```json opencode.json
{
  "$schema": "https://opencode.ai/config.json",
  "provider": {
    "morpheus-ai": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "Morpheus AI",
      "options": {
        "baseURL": "https://api.mor.org/api/v1"
      },
      "models": {
        "glm-4.6": {
          "name": "GLM 4.6"
        },
        "kimi-k2-thinking": {
          "name": "Kimi K2 Thinking"
        },
        "qwen3-coder-480b-a35b-instruct": {
          "name": "Qwen3 Coder 480B"
        }
      }
    }
  }
}
```

<Tip>
Start with a minimal configuration and add more models as needed. This keeps your model selection clean and focused.
</Tip>

## Setting Default Models

Configure your preferred models for different types of tasks:

```json opencode.json
{
  "$schema": "https://opencode.ai/config.json",
  "model": "morpheus-ai/glm-4.6",
  "small_model": "morpheus-ai/llama-3.3-70b",
  "provider": {
    "morpheus-ai": {
      ...
    }
  }
}
```

<ParamField path="model" type="string">
Default model used for main coding tasks, complex reasoning, and detailed responses.
</ParamField>

<ParamField path="small_model" type="string">
Faster, smaller model used for quick tasks like syntax checking, simple completions, and rapid iterations.
</ParamField>

## Using Morpheus AI in OpenCode

Once configured, restart OpenCode to load the new provider settings.

### Restart OpenCode

```bash
# Press Ctrl+C to exit the current session
# Then restart
opencode
```

### Select a Model

Use the `/models` command to view and select from available Morpheus AI models:

```
/models
```

You'll see all configured Morpheus AI models listed. Select one to start using it for your coding tasks.

<Tip>
Switch models at any time using the `/models` command. Different models excel at different tasks - experiment to find the best fit for your workflow.
</Tip>

### Start Coding

With Morpheus AI configured, you can now:

- **Generate code** - Ask for implementations, algorithms, or functions
- **Debug issues** - Get help troubleshooting errors and bugs
- **Refactor code** - Request improvements and optimizations
- **Explain code** - Understand complex codebases
- **Write tests** - Generate test cases and test suites

```
> Create a Python function that validates email addresses using regex

> Debug this TypeScript error: Type 'number' is not assignable to type 'string'

> Refactor this code to use async/await instead of callbacks

> Explain how this binary search algorithm works
```

## Available Models

The Morpheus marketplace offers a diverse range of models optimized for different tasks:

### Premium Models (Best Performance)

| Model | Context | Output | Best For |
|-------|---------|--------|----------|
| **Qwen3 Coder 480B** | 262K | 16K | Complex code generation, architecture design |
| **Hermes 3 Llama 405B** | 128K | 8K | Advanced reasoning, system design |
| **Kimi K2 Thinking** | 256K | 16K | Complex problem solving, multi-step reasoning |
| **GLM 4.6** | 200K | 65K | Long-form code generation, documentation |

### Balanced Models (Great All-Rounders)

| Model | Context | Output | Best For |
|-------|---------|--------|----------|
| **Qwen3 235B** | 131K | 8K | General coding tasks |
| **Llama 3.3 70B** | 128K | 8K | Code completion, debugging |
| **Qwen3 Next 80B** | 131K | 4K | Fast responses, quick iterations |
| **Mistral 31 24B** | 128K | 8K | Balanced performance, good reasoning |

### Lightweight Models (Fast & Efficient)

| Model | Context | Output | Best For |
|-------|---------|--------|----------|
| **Hermes 4 14B** | 128K | 4K | Quick completions, syntax help |
| **Qwen3 4B** | 131K | 4K | Simple tasks, rapid iteration |
| **Llama 3.2 3B** | 32K | 4K | Lightweight tasks, low-latency responses |

### Specialized Models

| Model | Context | Output | Best For |
|-------|---------|--------|----------|
| **Venice Uncensored** | 128K | 8K | Unrestricted content generation |

<Info>
Model availability depends on provider availability in the Morpheus marketplace. The API automatically routes to the highest-rated provider for your selected model. Check the [API documentation](https://apidocs.mor.org/api-reference/introduction) for the latest model availability.
</Info>

## Verifying Your Setup

### Check Authentication Status

Verify that your Morpheus AI credentials are stored correctly:

```bash
opencode auth list
```

You should see `morpheus-ai` in the list of configured credentials.

<Check>
If `morpheus-ai` appears in the list, your credentials are configured correctly.
</Check>

### Test the Connection

Start a conversation in OpenCode and ask a simple question:

```
> What is Python?
```

If you receive a response from the selected Morpheus AI model, your integration is working correctly!

## Troubleshooting

<AccordionGroup>
<Accordion title="Models not appearing in OpenCode">
**Cause**: Provider ID mismatch, configuration syntax error, or OpenCode not restarted.

**Solution**:
1. Verify the provider ID in both `/connect` and `opencode.json` exactly matches `morpheus-ai`
2. Check that your JSON configuration is valid (no missing commas, brackets)
3. Restart OpenCode completely
4. Verify credentials with `opencode auth list`

```bash
# Validate JSON syntax
cat ~/.config/opencode/opencode.json | python -m json.tool

# Check credentials
opencode auth list
```
</Accordion>

<Accordion title="Authentication errors when using models">
**Cause**: Invalid or expired API key, or incorrect provider configuration.

**Solution**:
1. Ensure your API key is valid and active at [app.mor.org](https://app.mor.org)
2. Verify the provider ID matches what you used in `/connect`
3. Try regenerating your API key if needed
4. Reconfigure credentials using `/connect` command

```bash
# Remove old credentials and reconfigure
opencode auth remove morpheus-ai
opencode
/connect
```
</Accordion>

<Accordion title="Connection errors or timeouts">
**Cause**: Network connectivity issues, firewall blocking, or service unavailability.

**Solution**:
1. Check your internet connection
2. Verify the baseURL is correct: `https://api.mor.org/api/v1`
3. Ensure your firewall allows HTTPS connections
4. Check the Morpheus AI service status

For large models like Qwen3 Coder 480B and Hermes 3 Llama 405B, timeouts are pre-configured to 600000ms (10 minutes). If you still experience timeouts, consider using a smaller model or checking your network connection.
</Accordion>

<Accordion title="Slow response times">
**Cause**: Large model selected, high marketplace demand, or network latency.

**Solution**:
- Use smaller models for quick tasks (e.g., `llama-3.3-70b`, `hermes-4-14b`)
- Configure a `small_model` in your `opencode.json` for rapid iterations
- Try different models to find the best balance of performance and speed
- Check your network latency to the Morpheus API

```json
{
  "model": "morpheus-ai/qwen3-coder-480b-a35b-instruct",
  "small_model": "morpheus-ai/hermes-4-14b"
}
```
</Accordion>

<Accordion title="Configuration file not found or ignored">
**Cause**: Wrong file location or OpenCode not looking in the right directory.

**Solution**:
1. For global configuration: `~/.config/opencode/opencode.json`
2. For project-specific: `./opencode.json` in your project root
3. Ensure the file has correct permissions
4. Verify JSON syntax is valid

```bash
# Create config directory if missing
mkdir -p ~/.config/opencode

# Set proper permissions
chmod 644 ~/.config/opencode/opencode.json
```
</Accordion>
</AccordionGroup>

## Best Practices

<CardGroup cols={2}>
<Card title="Choose the right model" icon="brain">
Select models based on your task complexity. Use large models for complex reasoning and smaller models for quick completions.
</Card>

<Card title="Configure small_model" icon="gauge-high">
Set a lightweight model as your `small_model` for faster responses on simple tasks, improving your coding workflow.
</Card>

<Card title="Secure your API key" icon="lock">
Never commit your API key to version control. Keep it in the secure OpenCode auth storage or environment variables.
</Card>

<Card title="Switch models freely" icon="shuffle">
Use the `/models` command to try different models. Each excels at different tasks - find what works best for you.
</Card>

<Card title="Use Web variants strategically" icon="globe">
Leverage `-web` suffix models when you need current information or web-enhanced responses. Use standard models for pure coding tasks.
</Card>

<Card title="Monitor performance" icon="chart-line">
Pay attention to response times and quality. Adjust your model selection based on your workflow needs.
</Card>
</CardGroup>

## Advanced Configuration

### Project-Specific Models

Override global settings for specific projects:

```json project-root/opencode.json
{
  "$schema": "https://opencode.ai/config.json",
  "model": "morpheus-ai/qwen3-coder-480b-a35b-instruct",
  "small_model": "morpheus-ai/qwen3-4b"
}
```

<Tip>
Use project-specific configurations when working on specialized projects that benefit from particular models.
</Tip>

### Custom Model Limits

Adjust context and output limits based on your needs:

```json opencode.json
{
  "provider": {
    "morpheus-ai": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "Morpheus AI",
      "options": {
        "baseURL": "https://api.mor.org/api/v1"
      },
      "models": {
        "custom-model": {
          "name": "Custom Model",
          "limit": {
            "context": 100000,
            "output": 4096
          },
          "options": {
            "timeout": 300000,
            "temperature": 0.7
          }
        }
      }
    }
  }
}
```

## Additional Resources

<CardGroup cols={2}>
<Card title="Morpheus AI Portal" icon="portal" href="https://app.mor.org">
  Manage your API keys, view usage, and access your Morpheus AI account.
</Card>

<Card title="API Documentation" icon="book" href="/api-reference/introduction">
  Complete reference documentation for the Morpheus API Gateway.
</Card>

<Card title="OpenCode Documentation" icon="code" href="https://opencode.ai/docs/providers">
  Learn more about OpenCode provider configuration and advanced features.
</Card>

<Card title="Community Support" icon="discord" href="https://opencode.ai/discord">
  Join the OpenCode Discord community for help and discussions.
</Card>
</CardGroup>

## Security Notes

<Warning>
Follow these security best practices to protect your API credentials:
</Warning>

- **Local storage**: Your API key is stored locally in `~/.local/share/opencode/auth.json`
- **Never commit keys**: Don't commit API keys or configuration files with credentials to public repositories
- **Add to .gitignore**: Include both `~/.config/opencode/opencode.json` and `~/.local/share/opencode/auth.json` in your `.gitignore` if sharing config files
- **Rotate compromised keys**: If your API key is compromised, immediately rotate it via the Morpheus AI dashboard
- **Use project configs carefully**: Ensure project-specific `opencode.json` files don't contain sensitive information

## Next Steps

Once configured, you can:

<Steps>
<Step title="Switch between models">
Use the `/models` command to select different models for various tasks and compare their performance.
</Step>

<Step title="Create project configurations">
Set up project-specific `opencode.json` files with models optimized for each project's needs.
</Step>

<Step title="Optimize your workflow">
Adjust context and output limits based on your typical use cases to balance performance and capability.
</Step>

<Step title="Monitor usage">
Track your usage and billing in the Morpheus AI dashboard at [app.mor.org](https://app.mor.org).
</Step>
</Steps>

## Summary

You've successfully integrated Morpheus AI with OpenCode! Here's what you've accomplished:

<Check>
**Credentials configured**: Added your Morpheus AI API key securely to OpenCode
</Check>

<Check>
**Provider setup**: Configured the Morpheus AI provider with access to powerful coding models
</Check>

<Check>
**Model selection**: Learned how to choose and switch between models for different tasks
</Check>

<Check>
**Best practices**: Understand security, performance optimization, and troubleshooting
</Check>

<Check>
**Free inference**: Enabled access to decentralized AI models during the Open Beta
</Check>

Happy coding with Morpheus AI! üöÄ
