---
title: "Quickstart"
description: "Start using the Morpheus Inference API in under 5 minutes"
---

# Quickstart

Get started with the Morpheus Inference API in just a few minutes. The API is fully **OpenAI-compatible**, meaning you can use existing OpenAI SDKs and tools with just a base URL change.

<Info>
**Base URL:** `https://api.mor.org/api/v1`

**Authentication:** Bearer token (your API key)
</Info>

## Step 1: Get Your API Key

1. Go to [app.mor.org](https://app.mor.org)
2. Create an account or sign in
3. Click **Create API Key** and copy it immediately

<Warning>
Your API key won't be shown again after creation. Store it securely.
</Warning>

## Step 2: Make Your First Request

The Morpheus Inference API is **fully OpenAI-compatible**. Simply change the base URL and use your Morpheus API key.

<Tabs>
<Tab title="curl">
```bash
curl https://api.mor.org/api/v1/chat/completions \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama-3.3-70b",
    "messages": [
      {"role": "user", "content": "Hello!"}
    ]
  }'
```
</Tab>

<Tab title="Python">
```python
from openai import OpenAI

client = OpenAI(
    api_key="YOUR_API_KEY",
    base_url="https://api.mor.org/api/v1"
)

response = client.chat.completions.create(
    model="llama-3.3-70b",
    messages=[
        {"role": "user", "content": "Hello!"}
    ]
)

print(response.choices[0].message.content)
```

Install the OpenAI SDK: `pip install openai`
</Tab>

<Tab title="JavaScript">
```javascript
import OpenAI from "openai";

const client = new OpenAI({
  apiKey: "YOUR_API_KEY",
  baseURL: "https://api.mor.org/api/v1",
});

const response = await client.chat.completions.create({
  model: "llama-3.3-70b",
  messages: [
    { role: "user", content: "Hello!" }
  ],
});

console.log(response.choices[0].message.content);
```

Install the OpenAI SDK: `npm install openai`
</Tab>

<Tab title="TypeScript">
```typescript
import OpenAI from "openai";

const client = new OpenAI({
  apiKey: process.env.MORPHEUS_API_KEY!,
  baseURL: "https://api.mor.org/api/v1",
});

const response = await client.chat.completions.create({
  model: "llama-3.3-70b",
  messages: [
    { role: "user", content: "Hello!" }
  ],
});

console.log(response.choices[0].message.content);
```

Install the OpenAI SDK: `npm install openai`
</Tab>
</Tabs>

## OpenAI Compatibility

The Morpheus Inference API implements the OpenAI API specification, ensuring compatibility with existing OpenAI clients and tools. You can switch from OpenAI to Morpheus with just two changes:

| Setting | OpenAI | Morpheus |
|---------|--------|----------|
| Base URL | `https://api.openai.com/v1` | `https://api.mor.org/api/v1` |
| API Key | `sk-...` (OpenAI key) | `sk-...` (Morpheus key) |

<Tip>
Any application that supports "OpenAI-compatible" APIs can work with Morpheus. This includes Cursor, Continue, LangChain, and hundreds of other tools.
</Tip>

## Streaming Responses

For real-time output, enable streaming:

<Tabs>
<Tab title="curl">
```bash
curl https://api.mor.org/api/v1/chat/completions \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama-3.3-70b",
    "messages": [
      {"role": "user", "content": "Write a haiku about AI"}
    ],
    "stream": true
  }'
```
</Tab>

<Tab title="Python">
```python
from openai import OpenAI

client = OpenAI(
    api_key="YOUR_API_KEY",
    base_url="https://api.mor.org/api/v1"
)

stream = client.chat.completions.create(
    model="llama-3.3-70b",
    messages=[
        {"role": "user", "content": "Write a haiku about AI"}
    ],
    stream=True
)

for chunk in stream:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="", flush=True)
```
</Tab>

<Tab title="JavaScript">
```javascript
import OpenAI from "openai";

const client = new OpenAI({
  apiKey: "YOUR_API_KEY",
  baseURL: "https://api.mor.org/api/v1",
});

const stream = await client.chat.completions.create({
  model: "llama-3.3-70b",
  messages: [
    { role: "user", content: "Write a haiku about AI" }
  ],
  stream: true,
});

for await (const chunk of stream) {
  if (chunk.choices[0]?.delta?.content) {
    process.stdout.write(chunk.choices[0].delta.content);
  }
}
```
</Tab>
</Tabs>

## Available Models

List available models to see what's currently active in the marketplace:

```bash
curl https://api.mor.org/api/v1/models \
  -H "Authorization: Bearer YOUR_API_KEY"
```

<Card title="View All Models" icon="sparkles" href="/documentation/models">
  See the complete list of available models with capabilities and context windows.
</Card>

## Next Steps

<CardGroup cols={2}>
<Card title="Available Models" icon="list" href="/documentation/models">
  Explore all available models and their capabilities.
</Card>

<Card title="Chat Completions" icon="message" href="/api-reference/chat/completions">
  Full API reference for chat completions.
</Card>

<Card title="OpenAI Python SDK" icon="python" href="/documentation/integrations/openai-python-sdk">
  Complete Python integration guide with streaming and tool calling.
</Card>

<Card title="Cursor Integration" icon="code" href="/documentation/integrations/cursor">
  Use Morpheus with Cursor IDE.
</Card>
</CardGroup>
